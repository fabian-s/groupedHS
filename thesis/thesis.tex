
\documentclass[12pt,letterpaper]{article} 
\usepackage[letterpaper,left=3.5cm,right=3.5cm, top=3.0cm, bottom=3.0cm, footnotesep=1.0cm]{geometry} 
\usepackage{mathptmx}
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}
\usepackage[onehalfspacing]{setspace} 
\usepackage{fancyhdr} 
\usepackage{relsize}

\usepackage[bottom]{footmisc}
\usepackage{tabularx}
\usepackage{mathtools}
\pagestyle{empty}        


\usepackage{booktabs}    
\usepackage{natbib}      
\usepackage{bibentry}   

\usepackage{acronym}
\usepackage{multicol}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage[usenames,dvipsnames]{color}
\usepackage{hyperref}

\lstset{language=R,
  basicstyle=\small\ttfamily,
  stringstyle=\color{ForestGreen},
  otherkeywords={0,1,2,3,4,5,6,7,8,9},
  morekeywords={TRUE,FALSE},
  deletekeywords={data,frame,length,as,character},
  keywordstyle=\color{blue},
  commentstyle=\color{ForestGreen},
}


\begin{document}

\begin{center}\uppercase{Ludwig-Maximilians-University Munich}\end{center}
\begin{center}\uppercase{Department of Statistics}\end{center}

\vspace{3cm}

\title{Variable selection using Grouped Horseshoe priors}
\date{\vspace{-5ex}}
{\let\newpage\relax\maketitle}
\thispagestyle{empty}


\begin{center}
  \begin{large}
    \begin{Large}
      Bachelor's Thesis\\
    \end{Large}
    Department of Statistics  \\
  \end{large}
\end{center}
\begin{center}
  Author:\\
  \begin{large}
    Tobias Pielok\\
  \end{large}
\end{center}
\vspace{1cm}
\begin{center}
  \begin{large}
    Supervisor: Dr. Fabian Scheipl
  \end{large}
\end{center}

\begin{center}  \begin{large}
    Submission date: \\%\date{\today} \\
  \end{large}
\end{center}

\vspace{1,5cm}

\begin{center}
  \begin{large}
    \author{Tobias Pielok, B.Sc. (TUM)}\\
 \end{large}
  Marchgrabenplatz 5\\ 
  80805 Munich\\ 
  \url{t.pielok@campus.lmu.de}\\
  Matrikelnr.:  11381351\\
\end{center}


\newpage
\setcounter{page}{1}
\tableofcontents
\newpage


\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0pt} 
\section*{Notation and Symbols}

\begin{tabular}{lll}
$\mathcal{B}_\mathcal{M}\bigotimes\mathcal{B}_\mathcal{N}$ & & product-$\sigma$-algebra generated by $\{M\times N :\; M\in\mathcal{B}_\mathcal{M}, N\in\mathcal{B}_\mathcal{N} \}$ \\
$\theta \in \mathbb{R}^d$ & & If $\theta$ is a random variable: $\theta$ maps to $\mathbb{R}^d$
\end{tabular}

\pagebreak
\section{Introduction}
\pagebreak

\section{Basic Concepts}
The foundation of Bayesian Horseshoe priors is based on the inference of the posterior distribution of the parameters, which can be attained by combining the prior knowledge of the parameters and the likelihood of the data, and will be introduced in section \ref{sec:BayInf}. In order of carrying out this inference it is necessary to sample from the posterior distribution.
In most cases this posterior distribution can be neither expressed in an analytical form nor are there standard samplers for it. Hence the HMC Method and its derivative NUTS will be shown in section \ref{sec:HMC}, with which it is possible to sample from the posterior distribution even in a high dimensional case. To express in this Bayesian framework the structure of grouped variables, on which the grouped Horseshoe priors will be later used in section \ref{sec:gHSP},  additive models will be introduced in section \ref{sec:AddMod}.
\subsection{Bayesian inference}
\label{sec:BayInf}
In Bayesian statistics the inference is carried out on the posterior distribution of a parameter $\tau$, after taking into account the realization of data $x$. In order of defining this posterior distribution thoroughly some rigorous definitions are needed:
Let $\mathcal{X}$ and $\mathcal{T}$ denote the \textit{sample space} and \textit{parameter space}, i.e. $\tau \in \mathcal{T}$ and $x \in \mathcal{X}$. Their $\sigma$-algebras will be called respectively $\mathcal{B}_\mathcal{X}$ and $\mathcal{B}_\mathcal{T}$. Also let the family of \textit{sampling distribution} $\mathcal{P} := \{P_\theta :\;\theta \in \mathcal{T}\}$, where $P_\theta$ is a probability measure over $(\mathcal{X}, \mathcal{B}_\mathcal{X})$. With these definitions a general \textit{statistical experiment} can be defined as $(\mathcal{X}, \mathcal{B}_\mathcal{X}, \mathcal{P})$ and for any given probability measure $\mu$ on $(\mathcal{T}, \mathcal{B}_\mathcal{T})$ a \textit{Bayesian experiment} can be identified with $(\mathcal{T}\times\mathcal{X},  \mathcal{B}_\mathcal{T}\bigotimes\mathcal{B}_\mathcal{X}, \Pi_{\mu,\mathcal{P}})$, where $\Pi_{\mu,\mathcal{P}}$ is the joint distribution of parameter-observation, s.t. $\forall T \in \mathcal{B}_\mathcal{T}, X \in \mathcal{B}_\mathcal{X}$:
\begin{equation}
\label{eq:likprio}
\Pi_{\mu,\mathcal{P}}(T,X) = \int_T P_\theta(X)\mu(d\theta ). 
\end{equation} 
The measure $\mu$ will be called the \textit{prior distribution} of the parameter. The \textit{predictive distribution} of the observations $P_{\mu,\mathcal{P}}$ is the marginal distribution of $\Pi_{\mu,\mathcal{P}}$ on $(\mathcal{X}, \mathcal{B}_\mathcal{X})$, s.t. $\forall X \in \mathcal{B}_\mathcal{X}: $
\begin{equation}
P_{\mu,\mathcal{P}}(X) = \Pi_{\mu,\mathcal{P}}(\mathcal{T},X).
\label{eq:pred}
\end{equation}
Eq. (\ref{eq:likprio}) can be rewritten with the predictive distribution (\ref{eq:pred}) and the family of \textit{posterior distributions} $\{\mu_\mathcal{P}(\cdot |\; x):\; x\in\mathcal{X}\}$, s.t. $\forall T \in \mathcal{B}_\mathcal{T}, X \in \mathcal{B}_\mathcal{X}$
\begin{equation}
\label{eq:post}
\Pi_{\mu,\mathcal{P}}(T,X) = \int_X \mu_\mathcal{P}(T|\; x) P_{\mu,\mathcal{P}}(dx ). 
\end{equation} 
Under the assumption that the Bayesian experiment $(\mathcal{T}\times\mathcal{X},  \mathcal{B}_\mathcal{T}\bigotimes\mathcal{B}_\mathcal{X}, \Pi_{\mu,\mathcal{P}})$ is dominated in the Bayesian setting (if not other stated, this will be assumed for the rest of the thesis) it can be shown (see [\cite{interbayes}]), that a posterior distribution for given $x$ can also be expressed with the Radon-Nikodym derivative, s.t. $\forall T \in \mathcal{B}_\mathcal{T}:$
\begin{equation}
\label{eq:dpost}
 \mu_\mathcal{P}(T|\; x) = \frac{\int_T \frac{dP_\theta}{d\lambda}(x)\mu(d\theta)}{\int_\mathcal{T} \frac{dP_\theta}{d\lambda}(x)\mu(d\theta)},
\end{equation} 
where $(\mathcal{X}, \mathcal{B}_\mathcal{X}, \mathcal{P})$ is dominated by a finite measure $\lambda$. The function $\frac{dP_\theta}{d\lambda}$ is called \textit{likelihood function}. 
%Why? -> inference%
\\An adequate choice of a point estimate to determine the location of the parameter $\theta$ depends on the underlying loss function. If a quadratic loss function $L$ is chosen, i.e. $L(\theta, \hat{\theta}) = ||\theta - \hat{\theta}||_2^2$, the expected loss $\mathbb{E}_{\theta \sim \mu} (L(\theta, \hat{\theta}))$ is minimized by the \textit{posterior mean} 
\begin{equation}
\label{eq:pmean}
	\hat{\theta} = E_{\theta |x \sim \mu_\mathcal{P}}(\theta |\; x),
\end{equation}
 if it exists (see [\cite{statdec}]). 
\\ A $100(1-\alpha)\%$ \textit{credible set} is a set $C \subset \mathcal{T}$, s.t.
\begin{equation}
1 - \alpha \leq P(C| \;x ) = \mu_\mathcal{P}(C|\; x).
\end{equation}
Which means that the parameter $\theta$ has the subjective probability of $(1-\alpha)$ that $\theta \in C$.
Because $C$ is not unique, additional constraints can be imposed on the solution. If the size of $C$, which can be defined as  $S(C) := \mu(C)$, is minimized one gets under mild conditions the  $100(1-\alpha)\%$  HDP credible set  as described in [\cite{statdec}], if there exists a posterior density $p_{\theta|\;x}$.
The  $100(1-\alpha)\%$ HDP credible set is defined as  
\begin{equation}
\label{eq:hdp}
C = \{\theta \in \mathcal{T}: \; p_{\theta|\;x}(\theta|\; x) \geq k(\alpha)\},
\end{equation}
where $k(\alpha)$ is the largest constant, s.t. $C$ is a $100(1-\alpha)\%$ credible set.
\newpage
\subsection{HMC and NUTS}
As already seen for carrying out the Bayesian inference the posterior distribution $\mu_\mathcal{P}$ is needed. In general solving Eq.  (\ref{eq:post}) or Eq. (\ref{eq:dpost}) for the posterior distribution is only in trivial cases analytically possible. Hence one tries to approximate the distribution by sampling from it. In most cases there is no standard sampler for $\mu_\mathcal{P}$. One way to overcome this problem, if there exist a corresponding probability density function $p(\theta)$ to $\mu_\mathcal{P}$, is to use the HMC method, where samples are drawn from a known distribution and with these samples of the desired distribution are computed. In HMC in order to sample a parameter $\theta$, for which it holds that $\theta \sim \mu_\mathcal{P}$ and $\theta \in \mathbb{R}^d$, an auxiliary variable $\rho$ is typically drawn from a multivariate normal distribution, s.t.
\begin{equation}
\rho \sim \mathcal{N}(0,\Sigma), 
\end{equation}
where $\rho \in \mathbb{R}^d$ and the covariance matrix $\Sigma \in \mathbb{R}^{d \times d}$. With the joint density $p(\rho, \theta)$ a so-called \textit{Hamiltonian} can be defined with regards of the canonical distribution as
\begin{equation}
H(\rho, \theta) = -\log p(\rho, \theta) = \underbrace{-\log p(\rho |\; \theta)}_{=:T(\rho |\; \theta)} \underbrace{-\log p(\theta)}_{=:V(\theta)},
\end{equation}
where T is called kinetic energy and V the potential energy. In general a Hamiltonian can be defined as follows:
Let $\rho,\theta \in (\mathbb{R}^d)^\mathbb{R}$ and $H(\rho,\theta)$ be scalar function sufficiently smooth.
$H$ is called a Hamiltonian if it holds that $\forall i \in \{1,\dots,d\}:$
\begin{equation}
\label{eq:hamdym}
\begin{aligned}
\frac{d \rho_i }{dt} = \frac{\partial H}{\partial \theta_i}, \\
\frac{d \theta_i }{dt} = -\frac{\partial H}{\partial \rho_i}.
\end{aligned}
\end{equation}
It can be shown that the Hamiltonian dynamics (\ref{eq:hamdym}) is reversible and preservers volume, which can even hold for the discretized version of the differential equations (see [\cite{mcmchb}]). With the \textit{leapfrog integrator}, which uses a discrete time step $\epsilon$, this can be achieved and (\ref{eq:hamdym}) can be solved numerically stable (see [\cite{mcmchb}]). Transitioning from a state $(\rho, \theta)$ to a new state $(\rho^*,\theta^*)$ in the leapfrog scheme, firstly a new  $\rho$ is drawn independently of $\theta$ and previous values of $\rho$ and secondly $L$ leapfrog steps are applied. One step of the leapfrog integrator can be summarized as follows:
\begin{enumerate}
\item The auxiliary variable $\rho$ is updated with half-step $\frac{\epsilon}{2}$ update using the negative derivative of the potential energy.
\label{en:f}
\item The parameter $\theta$ is updated with a full-step $\epsilon$ in the direction of the new $\rho$ multiplied with the derivative of the kinetic energy, which is represented by the covariance matrix $\Sigma$.
\item Another half-step $\frac{\epsilon}{2}$ update of $\rho$ as in \ref{en:f} is performed.
\end{enumerate}  
After $L$ leapfrog steps the proposal state $(\rho^*,\theta^*)$ is accepted as the new state with a probability of 
\[\min(1, \exp(H(\rho, \theta)-H(\rho^*,\theta^*))).
\] Otherwise $(\rho, \theta)$ is returned as the new state and hence also serves as the new initialization for the next iteration. This is called the Metropolis Accept Step.\\
 The series of by this scheme returned $\theta$ is also called a chain. As described in [\cite{convhmc}] under certain regularity conditions and control of the tail of posterior distribution $\mu_\mathcal{P}$ this chain is irreducible and (Harris) recurrent and $\mu_\mathcal{P}$ is its so-called invariant distribution. For a chain with these properties and under some additional assumptions it can be shown that with the use of ergodic theorems, that the chain  converges for almost every starting parameter $\theta_0$ in distribution to $\mu_\mathcal{P}$ and the law of large numbers and the central limit theorem are still valid, s.t. 
inferences (\ref{eq:pmean}) and (\ref{eq:hdp}) can be carried out approximately on a converged chain (see [\cite{mcstability}]). \\
The convergence speed of HMC is highly influenced by the hyper-parameters, i.e. the number of steps $L$, the step-size $\epsilon$ and the covariance matrix $\Sigma$.
One scheme to tune the parameter $L$ is NUTS. The advantage of using NUTS consists in its auto-tuning capability without the need to execute pre-runs. The general idea of NUTS can be described as follows: For the state $(\rho,\theta)$ the hamilitonian dynamics are simulated randomly both forwards and backwards in time to guarantee time reversibility. In every step the steps taken in one direction are doubled. The algorithm is stopped for a current $(\tilde{\theta},\tilde{\rho})$ when 
\begin{equation*}
\frac{d}{dt}\frac{||\tilde{\theta} - \theta||^2_2}{2} = (\tilde{\theta} -\theta )\frac{d}{dt}(\theta - \tilde{\theta}) = (\tilde{\theta} -\theta )\Sigma\tilde{\rho} < 0,
\end{equation*} i.e. the expected squared jump distance would shrink and the dynamics could be described as a \textit{U-turn}. From these simulated states new proposals are sampled (for further details see [\cite{nuts}]). 
\label{sec:HMC}
\subsection{Bayesian approach to Additive Models}
\label{sec:AddMod}
\pagebreak

\section{Bayesian Horseshoe}
\subsection{Mathematical foundations}
\subsection{Hyperprior choice for global shrinkage parameter}
\subsection{Extending Horseshoe prior to the case of grouped variables}
\label{sec:gHSP}
\subsection{Practical aspects}
\pagebreak

\section{Simulations}
\subsection{Settings}

\subsection{Szenario 1}
\subsubsection{Data generation}
\subsubsection{Results}
\subsection{Szenario 2}
\subsubsection{Data generation}
\subsubsection{Results}

\subsection{Summary}
\pagebreak

\section{Benchmarking}

\subsection{Regression}
\subsubsection{Data description}
\subsubsection{Comparisions and Results}
\subsection{Classification}
\subsubsection{Data description}
\subsubsection{Comparisions and Results}

\subsection{Summary}

\pagebreak

\section{Conclusions}
\pagebreak
\section{Appendix}
\subsection{Other variable selection methods}
\subsubsection{Spike-and-slab variable selection}
\subsubsection{Feature selection using LASSO}
\pagebreak
\subsection{Code}
\pagebreak

\pagestyle{fancy}
\bibliographystyle{apalike}
\bibliography{thesis} 

\nocite{*} 
\addcontentsline{toc}{section}{Bibliography}
\clearpage

\listoffigures
\addcontentsline{toc}{section}{List of Figures}
\clearpage


\section*{List of Abbreviations}
\addcontentsline{toc}{section}{List of Abbreviations}
\begin{multicols}{2}
  \begin{acronym}[abr]
    \acro{HMC}{Hamiltonian Monte Carlo}
    \acro{NUTS}{No-U-Turn Sampler}    
    \acro{HDP}{highest posterior density}       
    \acro{MCMC}{Markov Chain Monte Carlo}
  \end{acronym}
\end{multicols}



\pagebreak
\subsection*{Statement}
\label{erklaerung}
\vspace*{0.5cm}
I hereby declare that this thesis is my own original work and that all sources have been acknowledged.\\[1.0cm]
Munich, \today \\[2.0cm]
\rule{6.0cm}{0.4pt} \\
Tobias Pielok


\end{document}
